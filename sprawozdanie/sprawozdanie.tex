\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{ltablex}
\usepackage{makebox}
\usepackage{amsmath}
\usepackage{hyperref}

\studycycle{Informatyka, studia dzienne, II st.}
\coursesemester{II}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2011/2012}

\courseteacher{dr inż. Arkadiusz Tomczyk}
\coursegroup{poniedziałek, 10:15}

\author{
  \studentinfo{Michał Janiszewski}{169485} \and
  \studentinfo{Mariusz Łucka}{169493}
}

\title{Zadanie Numer 1: Ekstrakcja cech, miary podobieństwa, klasyfikacja}

\begin{document}
\maketitle

\section{Cel}
Celem zadania było stworzenie szkieletu aplikacji do klasyfikacji metodą k-NN na tyle uniwersalnego, żeby był niezależny od typu obiektów, które podlegają klasyfikacji.

Następnie dla zadanego zestawu danych tekstowych oraz zebranych przez siebie 100 krótkich tekstów należało zaimplementować dowolne dwie istniejące w literaturze metody ekstrakcji cech i dwie miary podobieństwa tekstów oraz metryki: euklidesowa, uliczna, Czebyszewa.

Kolejny krok to porównanie wyników dla poszczególnych metod oraz opcjonalnie zaproponowanie własnej metody ekstrakcji oraz miary podobieństwa, poprawiającej uzyskiwane wyniki. 

\section{Wprowadzenie}
\subsection{Algorytm k-NN}
Algorytm k najbliższych sąsiadów (lub algorytm k-nn z ang. \textit{k nearest neighbours}) jest jednym z algorytmów używanych do klasyfikacji danych. 

Algorytm zakłada istnienie zbioru uczącego zawierającego obserwacje, z których każda ma przypisany wektor zmiennych objaśniających $X$ oraz zmienną objaśnianą $Y$ (etykietę). Wtedy dla pewnej obserwacji $C$ z przypisanym wektorem zmiennych objaśniających $X$ możemy prognozować wartość zmiennej objaśnianej $Y$, czyli możemy dokonać klasyfikacji.

\paragraph{}
Algorytm polega na:

\begin{enumerate}
\item porównaniu wartości zmiennych objaśniających dla obserwacji $C$ z wartościami tych zmiennych dla każdej obserwacji w zbiorze uczącym (wg pewnej ustalonej metryki),
\item wyborze $k$ (ustalona z góry liczba) najbliższych do $C$ obserwacji ze zbioru uczącego,
\item wyborze etykiety $Y$, która występuje najczęściej wśród znalezionych $k$ obserwacji jako etykiety dla obserwacji $C$. 
\end{enumerate}

\subsection{Ekstrakcja cech tekstu}
Celem ekstrakcji cech tekstu jest reprezentacja tekstu w postaci wektorów cech, które następnie można porównać ze sobą. W przypadku tekstu za jego cechy można przyjąć występujące w nim słowa. Badanie wszystkich słów występujących w zbiorze dokumentów byłoby zbyt kosztowne, dlatego należy wybrać cześć z nich (słowa kluczowe), najlepiej charakteryzujące poszczególne dokumenty. Następnie dla każdego dokumentu należy utworzyć wektor wag liczbowych dla poszczególnych słów kluczowych.

\subsubsection{Liczba wystąpień słów}
Jedna z metod ograniczenia zbioru rozważanych słów polega na zliczeniu liczby wystąpień poszczególnych wyrazów w całym zbiorze dokumentów oraz odrzuceniu tych, które występują najczęściej i najrzadziej (odpowiednie progi należy dobrać doświadczalnie). W ten sposób usuwamy słowa niezwiązane z konkretną klasą dokumentów - słowa występujące tylko w pojedynczych dokumentach lub występujące w prawie każdym dokumencie jak na przykład spójniki, zaimki itd.


\subsubsection{Gęstość informacji}
Drugim wykorzystanym przez nas sposobem wybory słów kluczowych jest algorytm \textit{gęstości informacji}\footnote{W cytowanej literaturze opisywana metoda nie posiada nazwy.}
Dla danego zbioru $A_p$ dokumentów $X_i$ składających się ze słow $x_j$ poszukujemy takich słów, dla których parametr $f^k_l$, oznaczający liczbę wystąpień słowa $x_l$ w dokumencie $X_k$, spełnia następujące cechy:
\begin{equation}
 \exists_{A_1, A_2} A_1 \cup A_2 = A, A_1 \cap A_2 = \emptyset \mbox{ oraz } \forall_{X_i \in A_1} \forall_{X_j \in A_2} f^i_x \gg f^j_x
\end{equation}

Oznacza to, że poszukujemy słów, które występują głównie w ograniczonym zbiorze dokumentów i występują w nim dostatecznie często.

Określmy funkcję podobieństwa $P$ następująco:

\begin{equation}
 P(X_i, X_j) = \frac {\mu(X_i \cap X_j)} {\mu(X_i \cup X_j)}
\end{equation}

Po wyznaczeniu wszystkich wartości funkcji $P$ należy je zsumować z pominięciem głównej przekątnej uzyskanej macierzy:
\begin{equation}
 G = \sum _{i, j = 1; i \neq j}^{m} P(X_i, X_j)
\end{equation}
Otrzymaną w ten sposób wartość $G$ nazywać będziemy \textit{gęstością zbioru dokumentów}. Przez wartość $G_x$ oznaczymy gęstość dokumentów po usunięciu z nich słowa $x$.

\textit{Wartością dyskryminacyjną słowa $x$} będziemy nazywać wielkość $g(x)$ określoną w następujący sposób:
\begin{equation}
 g(x) = G_x - G
\end{equation}

Słowo $x$ zostanie wyznaczone jako możliwe słowo kluczowe (będzie \textit{dobrym dyskryminatorem}) jeśli będzie zwiększać gęstość zbioru dokumentów $A$ ($g(x) > 0$). Słowo $x$ zostanie odrzucone, jeśli jego wartość dyskryminacyjna będzie ujemna, ponieważ jego usunięcie zmniejsza gęstość zbioru dokumentów $A$.

\subsubsection{Algorytm TF-IDF}  
Do wyznaczenia wag poszczególnych słów kluczowych w tekstach można wykorzystać algorytm 
TF-IDF.

\paragraph{}
Wartość TF-IDF oblicza się ze wzoru:

$$ tf\mbox{-}idf)_{i,j} = tf_{i,j} \times  idf_{i}$$

Gdzie $tf_{i, j}$ to tzw. "term frequency", wyrażana wzorem:

$$ tf_{i,j} = \frac{n_{i,j}}{\sum_k n_{k,j}}$$

Gdzie $n_{i,j}$ jest liczbą wystąpień słowa $t_{i}$ w dokumencie $d_{j}$, a mianownik jest sumą liczby wystąpień wszystkich termów w dokumencie $d_{j}$.


$idf_{i}$ to "inverse document frequency", wyrażana wzorem:

$$idf_{i} =  \log \frac{|D|}{|\{d: t_{i} \in d\}}$$

Gdzie:\\
$|D|$ - liczba dokumentów w zbiorze\\
$|\{d : t_{i} \in d\}|$ - liczba dokumentów zawierających przynajmniej jedno wystąpienie danego słowa.

\paragraph{}
Wartość TF-IDF jest największa dla najlepszych słów kluczowych, czyli takich, które najlepiej pozwalają określić klasy dokumentów. Takie słowo występuje często w danym dokumencie, a jednocześnie pojawia się niewiele razy w innych dokumentach.


\subsection{Metryki odległości wektorów liczbowych}
W tym zadaniu należało zastosować następujące metryki wektorów liczbowych, reprezentujących wydobyte cechy tekstu:

\begin{enumerate}
\item Metryka euklidesowa $$d(x,y)=\sqrt{\sum_{i=1}^{n}{(x_i-y_i)^2} } $$
\item Metryka uliczna (Manhattan) $$d(x,y)=\sum_{i=1}^{n}{|x_i-y_i|} $$
\item Metryka Czebyszewa $$d(x,y)=\max_{i=1:n}(|x_i-y_i|) $$
\end{enumerate}
Metryki te są miarami odległości wektorów $x$ i $y$,. zatem im mniejsze wartości otrzymamy tym wektory leżą bliżej siebie.

\subsection{Miary podobieństwa tekstów}
W zadania zostały wykorzystane następujące dwie miary podobieństwa tekstów:

\begin{enumerate}
\item Miara Jaccarda: $$J(A,B)=\frac{\mu(A \cap B)}{\mu(A \cup B)}$$
gdzie $A$ i $B$ to zbiory słów w dwóch dokumentach a $\mu$ oznacza liczność zbioru.

\item Metoda n-gramów.\\
Określa podobieństwo łańcuchów tekstowych $s_1$ i $s_2$ w oparciu o ilość wspólnych podciągów n-elementowych:
$$sim_n(s_1, s_2)=\frac{1}{N-n+1}\sum_{i=1}^{N-n+1}h(i)$$
gdzie:\\
 $s_1$ i $s_2$ - badane łańcuchy tekstowe,\\
 $N$ - ilość podciągów n-elementowych w $s_1$,\\
 $n$ - długość podciągu,\\
 $h(i)=1$ - jeżeli i-ty podciąg z $s_1$ występuje w $s_2$,\\
 $h(i)=0$ - jeżeli i-ty podciąg z $s_1$ nie występuje w $s_2$.
\end{enumerate}
Dla ciągów identycznych miary podobieństwa przyjmują wartość 1, a dla zupełnie różnych wartość 0.


\section{Opis implementacji}
Aplikacja została podzielona na cztery główne moduły:
\begin{itemize}
 \item \verb|sgmlExtractor| \ppauza prosta aplikacja służąca do ekstrakcji danych z plików formatu \verb|SGML| na prostszy w obsłudze format,
 \item \verb|keywordSelector| \ppauza aplikacja służąca do wyboru słów kluczowych dla zadanego tekstu,
 \item \verb|stemmer| \ppauza aplikacja dokonująca rdzeniownie tekstu,
 \item \verb|classifier| \ppauza główna aplikacja zadania, która dokonuje klasyfikacji danych wejściowych.
\end{itemize}
Z wyjątkiem aplikacji \verb|stemmer|, wszystkie opisane powyżej aplikacje wykonane zotały przy użyciu frameworka \verb|Qt|, w języku \verb|C++|.

\subsection{sgmlExtractor}
Aplikacja ta ekstrahuje dane z pliku o strukturze \verb|SGML| do pliku o następującym formacie:
\begin{verbatim}
 etykieta1
 tekst1
 etykieta2
 tekst2
\end{verbatim}
Pozwala to na szybkie wczytanie danych, a także na ich łatwą interpretację przez człowieka \ppauza dane można edytować bez większych obaw o ,,zepsucie'' formatu pliku.

Aplikacja ta zawiera klasę \verb|SgmlReader|, która w metodzie \verb|readDirectory| przeszukuje żądany katalog w poszukiwaniu plików w formacie \verb|SGML|, a jeśli takie występują, to sprawdza zawarte w nich informacje pod kątem ustawionych wcześniej cech.

Zapis do nowego formatu wykonuje klasa \verb|ArticleWriter|.

\subsection{keywordSelector}
Aplikacja implementuje dwie metody wyboru słów kluczowych: \textit{gęstości informacji} oraz \textit{mutual information}, implementowane odpowiednio przez klasy   \verb|DiscriminatingExtractor| oraz \verb|MIExtractor|.

Obie metody odziedziczają interfejs \verb|KeywordExtractorInterface|, dzięki czemu możliwy jest dogodny wybór sposobu ekstrakcji słów kluczowych.

\subsection{stemmer}
Aplikacja została napisana w języku Java i wykorzystuje bibliotekę JWNL do połączenie ze słownikiem WordNet. Obsługa WordNeta jest realizowana w klasie \verb|WordNetStemmer|
 
WordNet jest słownikiem zawierającym bazę słów w języku angielskim razem z relacjami semantycznymi i leksykalnymi pomiędzy nimi. Umożliwia on m.in. rdzeniowanie (ang. \textit{stemming}) wyrazów, czyli otrzymanie formy podstawowej słowa. Dzięki zamianie wyrazów na ich formy podstawowe, odmiany tego samego słowa nie są rozróżniane, co ułatwia klasyfikację.

\subsection{classifier}
Aplikacja ta może działać w trzech trybach: klasyfikowania za pomocą metody $k$-NN, badania podobieństwa tekstów oraz ekstrakcji cech.

\subsubsection{Metoda $k$-NN}
\label{sec:impl_knn}
W trybie tym, zaraz po utworzeniu strumienia wyjściowego, sterowanie przekazywane jest do klasy \verb|Knn|, która inicjuje wybraną metrykę korzystając z fabryki \verb|MetricFactory|, a następnie za jej pomocą ładuje dane (które mogą być specyficzne dla żądanej metryki), po czym tworzy wątki \verb|KnnThread|, które dokonują obliczeń i wyznaczają odległości pomiędzy poszczególnymi obiektami zbiorów testowego i treningowego. Klasa \verb|Knn| konsoliduje wyniki i zapisuje je.

\subsubsection{Badanie podobieństwa tekstów}
Po wczytaniu artykułów za pomocą klasy \verb|ArticleLoader| następuje wyznaczenie wymaganych zbiorów słów, po czym podobnie jak w sekcji \ref{sec:impl_knn} sterowanie przekazywane jest do klasy \verb|Knn| z tą różnicą, że praca w tym przypadku wykonywana jest przez wątki klasy \verb|KnnSimiliarityThread|.

\subsubsection{Ekstrakcja cech}
Po wczytaniu artykułów za pomocą klasy \verb|ArticleLoader| wybierane są słowa, względem których liczone mają być wagi. Po zainicjowaniu wszystkich potrzebnych danych klasa \verb|Tfidf| wykonuje algorytm o tej samej nazwie.

\section{Materiały i metody}
Badania zostały przeprowadzone na dwóch zbiorach dokumentów tekstowych:\\
\begin{enumerate}
\item Zbiór dokumentów Reuters dostępny pod adresem:\\ \url{http://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection}\\\\
Dla tego zbioru testy były przeprowadzone w dwóch kategoriach:

\begin{itemize}
\item \textit{places} (etykiety: \textit{west-germany}, \textit{usa}, \textit{uk}, \textit{france}, \textit{canda}, \textit{japan}),
\item \textit{topics} (etykiety: \textit{coffee}, \textit{gold}, \textit{ship}, \textit{sugar}).\\
\end{itemize}
Wykorzystane zostały tylko artykuły, które w danej kategorii posiadają dokładnie jedną z wymienionych etykiet.\\


\item Zbiór wybranych na potrzeby tego zadania 100 krótkich opisów potraw ze strony \url{http://allrecipes.com}, z etykietami: \textit{cake} i \textit{pasta} (50 opisów dla każdej kategorii).

\end{enumerate}

\paragraph{}
We wszystkich badaniach zbiór danych został podzielony na 60\% danych uczących i 40\% danych testowych.
\paragraph{}
W każdym zbiorze tekstów zostały wyodrębnione wektory cech dla poszczególnych dokumentów metodami opisanymi w rozdziale 2, a następnie dokonano klasyfikacji za pomocą algorytmu k-NN dla $k$ z zakresu 1-100. W przypadku metody ekstrakcji opartej na liczbie wystąpień słów, jako słowa kluczowe wybrano te z zakresu 90-99\% najczęściej występujących, co dawało optymalne rezultaty.
Do badania odległości wektorów wykorzystano opisane wcześniej metryki: euklidesową, uliczną i Czebyszewa. Dla metryki euklidesowej i Czebyszewa została zastosowana normalizacja wektorów, ponieważ znacznie poprawiło to osiągane wyniki.\\
Również dla każdego zestawu tekstów policzono wartości podobieństwa ze tekstów zbioru treningowego do tekstów ze zbioru uczącego i dokonano klasyfikacji za pomocą k-NN.

Dodatkowo w celu poprawy otrzymywanych wyników została zastosowana zmodyfikowana przez nas metoda Jaccarda do określania podobieństwa tekstów: $$sim(d_1, d_2) = \sqrt{J(A ,B)*J(C, D)}$$\\
gdzie:\\
$A$ i $B$ to zbiory słów w dokumentach $d_1$ i $d_2$,\\
$C$ i $D$ to zbiory n-gramów 4-elementowych w dokumentach $d_1$ i $d_2$.


\section{Wyniki}
Poniższe tabele przedstawiają otrzymane podczas badań wyniki:

%tabela 1

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla metody ekstrakcji opartej na liczbie wystąpień słów i dla metryki euklidesowej.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 87.86\%	%1
& 85.03\%	%2
& 89.56\%	%3
& 88.91\%	%4
& 89.87\%	%5
& 90.04\%	%6
& 90.41\%	%7
& 90.17\%	%8
& 90.50\%	%9
& 90.17\%	%10
& 89.36\%	%20
& 88.64\%	%30
& 88.05\%	%60
& 86.86\%	%100
& 90.17\% (k=8,10)
\\ \hline
Reuters
- topics
& 91.26\%	%1
& 86.41\%	%2
& 90.29\%	%3
& 88.35\%	%4
& 91.26\%	%5
& 91.75\%	%6
& 93.20\%	%7
& 92.72\%	%8
& 93.20\%	%9
& 92.23\%	%10
& 92.23\%	%20
& 91.26\%	%40
& 91.75\%	%60
& 92.72\%	%100
& 93.20\% (k=7,9)
\\ \hline
Przepisy
- kulinarne 
& 77.5\%	%1
& 80\%		%2
& 80\%		%3
& 77.5\%	%4
& 77.5\%	%5
& 80\%		%6
& 75\%		%7
& 77.5\%	%8
& 77.5\%	%9
& 80\%		%10
& 90\%		%20
& 77.5\%	%40
& ---		%60
& ---		%100
& 90\% (k=20)
\\ \hline
\end{longtable}
}
\endgroup


%tabela 2

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla metody ekstrakcji opartej na liczbie wystąpień słów i dla metryki ulicznej.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 85.64\%	%1
& 71.25\%	%2
& 85.48\%	%3
& 74.63\%	%4
& 85.33\%	%5
& 84.52\%	%6
& 84.83\%	%7
& 84.29\%	%8
& 84.31\%	%9
& 83.92\%	%10
& 82.65\%	%20
& 81.26\%	%40
& 81.25\%	%60
& 81.23\%	%100
& 85.64\% (k=1)
\\ \hline
Reuters
- topics
& 91.26\%	%1
& 88.35\%	%2
& 89.81\%	%3
& 91.26\%	%4
& 91.26\%	%5
& 92.72\%	%6
& 91.75\%	%7
& 92.23\%	%8
& 91.75\%	%9
& 91.75\%	%10
& 91.75\%	%20
& 90.78\%	%40
& 89.32\%	%60
& 88.34\%	%100
& 92.72\%  (k=6)
\\ \hline
Przepisy
- kulinarne 
& 62.5\%	%1
& 57.5\%	%2
& 75\%		%3
& 62.5\%	%4
& 80\%		%5
& 72.5\%	%6
& 82.5\%	%7
& 75\%		%8
& 75\%		%9
& 77.5\%	%10
& 85\%		%20
& 82.5\%	%40
& ---		%60
& ---		%100
& 92.5\% (k=17)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 3

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla metody ekstrakcji opartej na liczbie wystąpień słów i dla metryki Czebyszewa.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 79.23\%	%1
& 72.71\%	%2
& 81.58\%	%3
& 81.67\%	%4
& 83.46\%	%5
& 83.70\%	%6
& 84.40\%	%7
& 84.29\%	%8
& 84.42\%	%9
& 84.52\%	%10
& 84.16\%	%20
& 83.09\%	%40
& 82.13\%	%60
& 81.41\%	%100
& 84.59\% (k=11)
\\ \hline
Reuters
- topics
& 75.73\%	%1
& 75.24\%	%2
& 74.76\%	%3
& 72.82\%	%4
& 70.87\%	%5
& 68.45\%	%6
& 68.93\%	%7
& 66.99\%	%8
& 66.99\%	%9
& 65.05\%	%10
& 57.28\%	%20
& 41.75\%	%40
& 34.95\%	%60
& 45.14\%	%100
& 75.73\%	(k=1)
\\ \hline
Przepisy
- kulinarne 
& 67.5\%	%1
& 72.5\%	%2
& 65\%		%3
& 75\%		%4
& 62.5\%	%5
& 67.5\%	%6
& 70\%		%7
& 72.5\%	%8
& 65\%		%9
& 72.5\%	%10
& 60\%		%20
& 52.5\%	%40
& ---		%60
& ---		%100
& 75\% (k=4)
\\ \hline
\end{longtable}
}
\endgroup




%tabela 4

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla metody gęstości informacji i metryki euklidesowej.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 79.18\%	%1
& 77.72\%	%2
& 79.93\%	%3
& 79.38\%	%4
& 80.27\%	%5
& 79.97\%	%6
& 80.48\%	%7
& 80.43\%	%8
& 80.88\%	%9
& 80.88\%	%10
& 80.91\%	%20
& 80.86\%	%40
& 80.86\%	%60
& 80.78\%	%100
& 81.02\% (k=24)

\\ \hline
Reuters
- topics
& 77.72\%	%1
& 77.45\%	%2
& 76.52\%	%3
& 73.52\%	%4
& 70.91\%	%5
& 69.55\%	%6
& 69.01\%	%7
& 67.12\%	%8
& 66.56\%	%9
& 66.32\%	%10
& 60.36\%	%20
& 40.65\%	%40
& 38.45\%	%60
& 47.32\%	%100
& 77.72\%	(k=1)
\\ \hline
Przepisy
- kulinarne 
& 60\%		%1
& 62.5\%	%2
& 62.5\%	%3
& 65\%		%4
& 67.5\%	%5
& 70\%		%6
& 75\%		%7
& 70\%		%8
& 70\%		%9
& 65\%		%10
& 45\%		%20
& 45\%		%40
& ---		%60
& ---		%100
& 75\% (k=7)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 5

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla pierwszej metody ekstrakcji i metryki ulicznej.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 77.77\%	%1
& 74.43\%	%2
& 79.99\%	%3
& 79.36\%	%4
& 80.97\%	%5
& 80.61\%	%6
& 81.04\%	%7
& 81.08\%	%8
& 81.34\%	%9
& 81.67\%	%10
& 81.32\%	%20
& 80.88\%	%40
& 80.32\%	%60
& 80.16\%	%100
& 81.67\% (k=10)
\\ \hline
Reuters
- topics
& 77.03\%	%1
& 77.42\%	%2
& 75.37\%	%3
& 74.52\%	%4
& 72.42\%	%5
& 70.54\%	%6
& 69.99\%	%7
& 68.13\%	%8
& 64.69\%	%9
& 65.01\%	%10
& 60.45\%	%20
& 43.88\%	%40
& 35.56\%	%60
& 47.64\%	%100
& 77.42\%	(k=2)
\\ \hline
Przepisy
- kulinarne 
& 72.5\%	%1
& 72.5\%	%2
& 75\%		%3
& 77.5\%	%4
& 72.5\%	%5
& 70\%		%6
& 65\%		%7
& 62.5\%	%8
& 62.5\%	%9
& 65\%		%10
& 60\%		%20
& 45\%		%40
& ---		%60
& ---		%100
& 77.5\% (k=4)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 6

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla metody gęstości informacji i metryki Cebyszewa.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 79.84\%	%1
& 79.84\%	%2
& 79.84\%	%3
& 79.84\%	%4
& 79.84\%	%5
& 79.84\%	%6
& 79.84\%	%7
& 79.84\%	%8
& 79.84\%	%9
& 79.84\%	%10
& 79.84\%	%20
& 79.84\%	%40
& 79.84\%	%60
& 79.84\%	%100
& 79.84\% (k=1-100)
\\ \hline
Reuters
- topics
& 60.32\%	%1
& 60.32\%	%2
& 60.32\%	%3
& 60.32\%	%4
& 60.32\%	%5
& 60.32\%	%6
& 60.32\%	%7
& 60.32\%	%8
& 60.32\%	%9
& 60.32\%	%10
& 60.32\%	%20
& 60.32\%	%40
& 60.32\%	%60
& 60.32\%	%100
& 60.32\% (k=1-100)
\\ \hline
Przepisy
- kulinarne 
& 60\%	%1
& 60\%	%2
& 60\%		%3
& 60\%	%4
& 60\%	%5
& 60\%		%6
& 60\%		%7
& 60\%	%8
& 60\%	%9
& 60\%		%10
& 60\%		%20
& 60\%		%40
& ---		%60
& ---		%100
& 60\% (k=1-100)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 7

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla podobieństwa tekstów za pomocą miary Jaccarda.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 88.30\%	%1
& 85.83\%	%2
& 89.70\%	%3
& 89.67\%	%4
& 89.67\%	%5
& 89.32\%	%6
& 89.63\%	%7
& 89.63\%	%8
& 89.62\%	%9
& 89.63\%	%10
& 88.71\%	%20
& 86.83\%	%40
& 85.55\%	%60
& 83.92\%	%100
& 89.70\%	(k=3)
\\ \hline
Reuters
- topics
& 85.92\%	%1
& 82.52\%	%2
& 83.98\%	%3
& 83.50\%	%4
& 86.41\%	%5
& 87.86\%	%6
& 87.86\%	%7
& 83.98\%	%8
& 86.89\%	%9
& 86.41\%	%10
& 86.89\%	%20
& 85.44\%	%40
& 81.55\%	%60
& 82.04\%	%100
& 87.86\%	(k=6,7)
\\ \hline
Przepisy
- kulinarne 
& 85\%		%1
& 80\%		%2
& 85\%		%3
& 82.5\%	%4
& 85\%		%5
& 82.5\%	%6
& 87.5\%	%7
& 82.5\%	%8
& 90\%		%9
& 82.5\%	%10
& 85\%		%20
& 87.5\%	%40
& ---		%60
& ---		%100
& 90\% (k=9)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 8

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla podobieństwa tekstów za pomocą n-gramów 4-elementowych.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 78.38\%	%1
& 75.96\%	%2
& 79.73\%	%3
& 79.36\%	%4
& 80.11\%	%5
& 80.14\%	%6
& 80.49\%	%7
& 80.34\%	%8
& 80.49\%	%9
& 80.38\%	%10
& 80.43\%	%20
& 80.24\%	%40
& 80.21\%	%60
& 80.24\%	%100
& 80.54\%	(k=16)
\\ \hline
Reuters
- topics
& 60.19\%	%1
& 57.77\%	%2
& 63.59\%	%3
& 61.17\%	%4
& 61.17\%	%5
& 59.71\%	%6
& 61.17\%	%7
& 59.71\%	%8
& 61.66\%	%9
& 61.66\%	%10
& 66.50\%	%20
& 71.36\%	%40
& 70.87\%	%60
& 74.27\%	%100
& 75.72\%	(k=97)
\\ \hline
Przepisy
- kulinarne 
& 77.5\%	%1
& 70\%		%2
& 82.5\%	%3
& 72.5\%	%4
& 75\%		%5
& 72.5\%	%6
& 82.5\%	%7
& 80\%		%8
& 87.5\%	%9
& 87.5\%	%10
& 82.5\%	%20
& 92.5\%	%40
& ---		%60
& ---		%100
& 95\% (k=41)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 9

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla podobieństwa tekstów za pomocą zmodyfikowanej miary Jaccarda.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 88.54\%	%1
& 85.64\%	%2
& 89.39\%	%3
& 89.49\%	%4
& 90.23\%	%5
& 89.89\%	%6
& 89.78\%	%7
& 89.87\%	%8
& 89.63\%	%9
& 89.65\%	%10
& 88.34\%	%20
& 86.66\%	%40
& 85.35\%	%60
& 83.70\%	%100

& 90.23\%	(k=5)
\\ \hline
Reuters
- topics
& 83.98\%	%1
& 82.52\%	%2
& 84.46\%	%3
& 86.41\%	%4
& 84.95\%	%5
& 88.35\%	%6
& 87.38\%	%7
& 85.44\%	%8
& 85.92\%	%9
& 85.44\%	%10
& 81.55\%	%20
& 80.10\%	%40
& 81.07\%	%60
& 81.07\%	%100

& 88.35\%	(k=6)
\\ \hline
Przepisy
- kulinarne 
& 92.5\%	%1
& 82.5\%	%2
& 80\%		%3
& 80\%		%4
& 80\%		%5
& 77.5\%	%6
& 80\%		%7
& 77.5\%	%8
& 85\%		%9
& 82.5\%	%10
& 85\%		%20
& 85\%		%40
& ---		%60
& ---		%100
& 92.5\% (k=1,13)
\\ \hline
\end{longtable}
}
\endgroup



\section{Dyskusja}
W metodzie $k$-NN metryka Czebyszewa daje najgorsze wyniki spośród badanych metryk, ponieważ jest bardzo wrażliwa na maksymalną różnicę współrzędnych i nawet jeżeli pozostałe współrzędne są podobne, to wektory są klasyfikowane jako odległe od siebie. Metryki euklidesowa i uliczna dają podobne, dobre rezultaty, chociaż metryka euklidesowa jest nieznacznie lepsza.

Współczynnik Jaccarda dobrze sprawdza się jako miara podobieństwa tekstów. Metoda n-gramów jest skuteczna jedynie dla tekstów gdzie we wszystkich artykułach w danej kategorii występują podobne słowa (przypadek dla przepisow kulinarnych).

Jak pokazuje zmodyfikowana przez nas miara Jaccarda, połączenie ze sobą kilku metod może przynieść poprawę wyników; do uzyskania znacznej poprawy konieczna jest jednak dogłębna znajomość dziedziny.

Metoda ekstrakcji cech tekstów oparta na liczbie wystąpień słów, pomimo że wydaje się prosta, okazała się dużo bardziej skuteczna od metody gęstości informacji

Zaimplementowane Metody nie sprawiają wrażenia złożonych obliczeniowo, jednak ilość danych, jaką muszą one przetworzyć jest znaczna. Implementacja metod jest bardzo dobrym polem do optymalizacji, niejednokrotnie zdarzało się nam przyspieszyć program o więcej niż 2x. Wciąż nie pozwoliło to jednak na policzenie wyników w rozsądnym czasie dla wszystkich testów \ppauza z części testów musieliśmy zrezygnować.

\section{Wnioski}
\begin{itemize}
 \item Zmiana metryki w metodzie $k$-NN powoduje duże zmiany skuteczności.
 \item Nie ma metody uniwersalnej, skuteczność jest zależna od dobranych parametrów.
 \item Do klasyfikacji przydaje się wszelka wiedza o klasyfikowanych obiektach.
 \item Często należy ręcznie dobrać parametry metod.
\end{itemize}

\begin{thebibliography}{0}
	\bibitem .http://ics.p.lodz.pl/~aniewiadomski/ksr/ksr-wyklad-2009.pdf
	\bibitem .http://microarray.republika.pl/pdf/Dod\_B1.pdf	
	\bibitem .http://pl.wikipedia.org/wiki/Algorytm\_k\_najbli\%C5\%BCszych\_s\%C4\%85siad\%C3\%B3w
	\bibitem .http://pl.wikipedia.org/wiki/TFIDF
	
\end{thebibliography}
\end{document}
