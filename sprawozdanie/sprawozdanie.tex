\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{ltablex}
\usepackage{makebox}
\usepackage{amsmath}
\usepackage{hyperref}

\studycycle{Informatyka, studia dzienne, II st.}
\coursesemester{II}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2011/2012}

\courseteacher{dr inż. Arkadiusz Tomczyk}
\coursegroup{poniedziałek, 10:15}

\author{
  \studentinfo{Michał Janiszewski}{169485} \and
  \studentinfo{Mariusz Łucka}{169493}
}

\title{Zadanie Numer 1: Ekstrakcja cech, miary podobieństwa, klasyfikacja}
\svnurl{}

\begin{document}
\maketitle

\section{Cel}
Celem zadania było stworzenie szkieletu aplikacji do klasyfikacji metodą k-NN na tyle uniwersalnego, żeby był niezależny od typu obiektów, które podlegają klasyfikacji.

Następnie dla zadanego zestawu danych tekstowych oraz zebranych przez siebie 100 krótkich tekstów należało zaimplementować dowolne dwie istniejące w literaturze metody ekstrakcji cech i dwie miary podobieństwa tekstów oraz metryki: euklidesowa, uliczna, Czebyszewa.

Kolejny krok to porównanie wyników dla poszczególnych metod oraz opcjonalnie zaproponowanie własnej metody ekstrakcji oraz miary podobieństwa, poprawiającej uzyskiwane wyniki. 

\section{Wprowadzenie}
\subsection{Algorytm k-nn}
Algorytm k najbliższych sąsiadów (lub algorytm k-nn z ang. \textit{k nearest neighbours}) jest jednym z algorytmów używanych do klasyfikacji danych. 

Algorytm zakłada istnienie zbioru uczącego zawierającego obserwacje, z których każda ma przypisany wektor zmiennych objaśniających $X$ oraz zmienną objaśnianą $Y$ (etykietę). Wtedy dla pewnej obserwacji $C$ z przypisanym wektorem zmiennych objaśniających $X$ możemy prognozować wartość zmiennej objaśnianej $Y$, czyli możemy dokonać klasyfikacji.

\paragraph{}
Algorytm polega na:

\begin{enumerate}
\item porównaniu wartości zmiennych objaśniających dla obserwacji $C$ z wartościami tych zmiennych dla każdej obserwacji w zbiorze uczącym (wg pewnej ustalonej metryki),
\item wyborze $k$ (ustalona z góry liczba) najbliższych do $C$ obserwacji ze zbioru uczącego,
\item wyborze etykiety $Y$, która występuje najczęściej wśród znalezionych $k$ obserwacji jako etykiety dla obserwacji $C$. 
\end{enumerate}

\subsection{Ekstrakcja cech tekstu}
Celem ekstrakcji cech tekstu jest reprezentacja tekstu w postaci wektorów cech, które następnie można porównać ze sobą. W przypadku tekstu za jego cechy można przyjąć występujące w nim słowa. Badanie wszystkich słów występujących w zbiorze dokumentów byłoby zbyt kosztowne, dlatego należy wybrać cześć z nich (słowa kluczowe), najlepiej charakteryzujących poszczególne dokumenty. Następnie dla każdego dokumentu należy utworzyć wektor wag liczbowych poszczególnych słów kluczowych.

\paragraph{}
Jedna z metod ograniczenia zbioru rozważanych słów polega na zliczeniu ilość wystąpień poszczególnych słów w całym zbiorze dokumentów oraz odrzuceniu tych które występują najczęściej i najrzadziej (odpowiednie progi należy dobrać doświadczalnie). W ten sposób usuwamy słowa niezwiązane z konkretną klasą dokumentów - słowa występujące tylko w pojedynczych dokumentach lub występujące w prawie każdym dokumencie jak na przykład spójniki, zaimki itd.

Do wyboru słów kluczowych wykorzystaliśmy dwa algorytmy: \textit{gęstości informacji}\footnote{W cytowanej literaturze opisywana metoda nie posiada nazwy.} oraz \textit{mutual information}\footnote{Ze względu na nieznajomość polskiego tłumaczenia tej nazwy, będziemy używać jej oryginalnego określenia. Gdybyśmy mieli nazwę tę przetłumaczyć, brzmiałaby ona następująco: ,,metoda informacji wspólnej''.}

\subsubsection{Gęstość informacji}
Dla danego zbioru $A_p$ dokumentów $X_i$ składających się ze słow $x_j$ poszukujemy takich słów, dla których parametr $f^k_l$, oznaczający liczbę wystąpień słowa $x_l$ w dokumencie $X_k$, spełnia następujące cechy:
\begin{equation}
 \exists_{A_1, A_2} A_1 \cup A_2 = A, A_1 \cap A_2 = \emptyset \mbox{ oraz } \forall_{X_i \in A_1} \forall_{X_j \in A_2} f^i_x \gg f^j_x
\end{equation}

Oznacza to, że poszukujemy słów, które występują głównie w ograniczonym zbiorze dokumentów i występują w nim dostatecznie często.

Określmy funkcję podobieństwa $P$ następująco:

\begin{equation}
 P(X_i, X_j) = \frac {\mu(X_i \cap X_j)} {\mu(X_i \cup X_j)}
\end{equation}

Po wyznaczeniu wszystkich wartości funkcji $P$ należy je zsumować z pominięciem głównej przekątnej uzyskanej macierzy:
\begin{equation}
 G = \sum _{i, j = 1; i \neq j}^{m} P(X_i, X_j)
\end{equation}
Otrzymaną w ten sposób wartość $G$ nazywać będziemy \textit{gęstością zbioru dokumentów}. Przez wartość $G_x$ oznaczymy gęstość dokumentów po usunięciu z nich słowa $x$.

\textit{Wartością dyskryminacyjną słowa $x$} będziemy nazywać wielkość $g(x)$ określoną w następujący sposób:
\begin{equation}
 g(x) = G_x - G
\end{equation}

Słowo $x$ zostanie wyznaczone jako możliwe słowo kluczowe (będzie \textit{dobrym dyskryminatorem}) jeśli będzie zwiększać gęstość zbioru dokumentów $A$ ($g(x) > 0$). Słowo $x$ zostanie odrzucone, jeśli jego wartość dyskryminacyjna będzie ujemna, ponieważ jego usunięcie zmniejsza gęstość zbioru dokumentów $A$.

  
Do wyznaczenia wag poszczególnych słów kluczowych w tesktach można wykorzystać algorytm 
\textbf{TF-IDF}.

\paragraph{}
Wartość TF-IDF oblicza się ze wzoru:

$$ tf\mbox{-}idf)_{i,j} = tf_{i,j} \times  idf_{i}$$

Gdzie $tf_{i, j}$ to tzw. "term frequency", wyrażana wzorem:

$$ tf_{i,j} = \frac{n_{i,j}}{\sum_k n_{k,j}}$$

Gdzie $n_{i,j}$ jest liczbą wystąpień słowa $t_{i}$ w dokumencie $d_{j}$, a mianownik jest sumą liczby wystąpień wszystkich termów w dokumencie $d_{j}$.


$idf_{i}$ to "inverse document frequency", wyrażana wzorem:

$$idf_{i} =  \log \frac{|D|}{|\{d: t_{i} \in d\}}$$

Gdzie:
$|D|$ - liczba dokumentów w zbiorze\\
$|\{d : t_{i} \in d\}|$ - liczba dokumentów zawierających przynajmniej jedno wystąpienie danego słowa.

\paragraph{}
Wartość TF-IDF jest największa dla najlepszych słów kluczowych, czyli takich, które najlepiej pozwalają określić klasy dokumentów. Takie słowo występuje często w danym dokumencie, a jednocześnie pojawia się niewiele razy w innych dokumentach.


\subsection{Metryki odległości wektorów liczbowych}
W tym zadaniu należało zastosować następujące metryki wektorów liczbowych, reprezentujących wydobyte cechy tekstu:

\begin{enumerate}
\item Metryka euklidesowa $$d(x,y)=\sqrt{\sum_{i=1}^{n}{(x_i-y_i)^2} } $$
\item Metryka uliczna (Manhattan) $$d(x,y)=\sum_{i=1}^{n}{|x_i-y_i|} $$
\item Metryka Czebyszewa $$d(x,y)=\max_{i=1:n}(|x_i-y_i|) $$
\end{enumerate}
Metryki te są miarami odległości wektorów $x$ i $y$,. zatem im mniejsze wartości otrzymamy tym wektory leżą bliżej siebie.

\subsection{Miary podobieństwa tekstów}
W zadania zostały wykorzystane następujące dwie miary podobieństwa tekstów:

\begin{enumerate}
\item Miara Jaccarda: $$J(A,B)=\frac{\mu(A \cap B)}{\mu(A \cup B)}$$
gdzie $A$ i $B$ to zbiory słów w dwóch dokumentach a $\mu$ oznacza liczność zbioru.

\item Metoda n-gramów.\\
Określa podobieństwo łańcuchów tekstowych $s_1$ i $s_2$ w oparciu o ilość wspólnych podciągów n-elementowych:
$$sim_n(s_1, s_2)=\frac{1}{N-n+1}\sum_{i=1}^{N-n+1}h(i)$$
gdzie:\\
 $s_1$ i $s_2$ - badane łańcuchy tekstowe,\\
 $N$ - ilość podciągów n-elementowych w $s_1$,\\
 $n$ - długość podciągu,\\
 $h(i)=1$ - jeżeli i-ty podciąg z $s_1$ występuje w $s_2$,\\
 $h(i)=0$ - jeżeli i-ty podciąg z $s_1$ nie występuje w $s_2$.
\end{enumerate}
Dla ciągów identycznych miary podobieństwa przyjmują wartość 1, a dla zupełnie różnych wartość 0.


\section{Opis implementacji}
Aplikacja została podzielona na cztery główne moduły:
\begin{itemize}
 \item \verb|sgmlExtractor| \ppauza prosta aplikacja służąca do ekstrakcji danych z plików formatu \verb|SGML| na prostszy w obsłudze format,
 \item \verb|keywordSelector| \ppauza aplikacja służąca do wyboru słów kluczowych dla zadanego tekstu,
 \item \verb|stemmer| \ppauza aplikacja dokonująca rdzeniownie tekstu,
 \item \verb|classifier| \ppauza główna aplikacja zadania, która dokonuje klasyfikacji danych wejściowych.
\end{itemize}
Z wyjątkiem aplikacji \verb|stemmer|, wszystkie opisane powyżej aplikacje wykonane zotały przy użyciu frameworka \verb|Qt|, w języku \verb|C++|.

\subsection{sgmlExtractor}
Aplikacja ta ekstrahuje dane z pliku o strukturze \verb|SGML| do pliku o następującym formacie:
\begin{verbatim}
 etykieta1
 tekst1
 etykieta2
 tekst2
\end{verbatim}
Pozwala to na szybkie wczytanie danych, a także na ich łatwą interpretację przez człowieka \ppauza dane można edytować bez większych obaw o ,,zepsucie'' formatu pliku.

Aplikacja ta zawiera klasę \verb|SgmlReader|, która w metodzie \verb|readDirectory| przeszukuje żądany katalog w poszukiwaniu plików w formacie \verb|SGML|, a jeśli takie występują, to sprawdza zawarte w nich informacje pod kątem ustawionych wcześniej cech.

Zapis do nowego formatu wykonuje klasa \verb|ArticleWriter|.

\subsection{keywordSelector}
Aplikacja implementuje dwie metody wyboru słów kluczowych: \textit{gęstości informacji} oraz \textit{mutual information}, implementowane odpowiednio przez klasy   \verb|DiscriminatingExtractor| oraz \verb|MIExtractor|.

Obie metody odziedziczają interfejs \verb|KeywordExtractorInterface|, dzięki czemu możliwy jest dogodny wybór sposobu ekstrakcji słów kluczowych.

\subsection{stemmer}
{\color{red} OPPISAĆ STEMMER w kilku slowach}

\subsection{classifier}
Aplikacja ta może działać w trzech trybach: klasyfikowania za pomocą metody $k$-NN, badania podobieństwa tekstów oraz ekstrakcji cech.

\subsubsection{Metoda $k$-NN}
\label{sec:impl_knn}
W trybie tym, zaraz po utworzeniu strumienia wyjściowego, sterowanie przekazywane jest do klasy \verb|Knn|, która inicjuje wybraną metrykę korzystając z fabryki \verb|MetricFactory|, a następnie za jej pomocą ładuje dane (które mogą być specyficzne dla żądanej metryki), po czym tworzy wątki \verb|KnnThread|, które dokonują obliczeń i wyznaczają odległości pomiędzy poszczególnymi obiektami zbiorów testowego i treningowego. Klasa \verb|Knn| konsoliduje wyniki i zapisuje je.

\subsubsection{Badanie podobieństwa tekstów}
Po wczytaniu artykułów za pomocą klasy \verb|ArticleLoader| następuje wyznaczenie wymaganych zbiorów słów, po czym podobnie jak w sekcji \ref{sec:impl_knn} sterowanie przekazywane jest do klasy \verb|Knn| z tą różnicą, że praca w tym przypadku wykonywana jest przez wątki klasy \verb|KnnSimiliarityThread|.

\subsubsection{Ekstrakcja cech}
Po wczytaniu artykułów za pomocą klasy \verb|ArticleLoader| wybierane są słowa, względem których liczone mają być wagi. Po zainicjowaniu wszystkich potrzebnych danych klasa \verb|Tfidf| wykonuje algorytm o tej samej nazwie.

\section{Materiały i metody}
Badania zostały przeprowadzone na dwóch zbiorach dokumentów tekstowych:\\
\begin{enumerate}
\item Zbiór dokumentów Reuters dostępny pod adresem:\\ \url{http://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection}\\\\
Dla tego zbioru testy były przeprowadzone w dwóch kategoriach:

\begin{itemize}
\item \textit{places} (etykiety: \textit{west-germany}, \textit{usa}, \textit{uk}, \textit{france}, \textit{canda}, \textit{japan}),
\item \textit{topics} (etykiety: \textit{coffee}, \textit{gold}, \textit{ship}, \textit{sugar}).\\
\end{itemize}
Wykorzystane zostały tylko artykuły, które w danej kategorii posiadają dokładnie jedną z wymienionych etykiet.\\


\item Zbiór wybranych na potrzeby tego zadania 100 krótkich opisów potraw ze strony \url{http://allrecipes.com}, z etykietami: \textit{cake} i \textit{pasta} (50 opisów dla każdej kategorii).

\end{enumerate}

\paragraph{}
We wszystkich badaniach zbiór danych został podzielony na 60\% danych uczących i 40\% danych testowych.
\paragraph{}
W każdym zbiorze tekstów zostały wyodrębnione wektory cech dla poszczególnych dokumentów metodami opisanymi w rozdziale 2, a następnie dokonano klasyfikacji za pomocą algorytmu k-NN dla $k$ z zakresu 1-100. Do badania odległości wektorów wykorzystano opisane wcześniej metryki: eklidesową, uliczną i Czebyszewa.\\
Również dla każdego zestawu tekstów policzono wartości podobieństwa ze tekstów zbioru treningowego do tekstów ze zbioru uczącego i dokonano klasyfikacji za pomocą k-NN.

Dodatkowo w celu poprawy otrzymywanych wyników została zastosowana zmodyfikowana przez nas metoda Jaccarda do określania podobieństwa tekstów: $$sim(d_1, d_2) = \sqrt{J(A ,B)*J(C, D)}$$\\
gdzie:\\
$A$ i $B$ to zbiory słów w dokumentach $d_1$ i $d_2$,\\
$C$ i $D$ to zbiory n-gramów 4-elementowych w dokumentach $d_1$ i $d_2$.

\paragraph{} 
{\color{red}OPISAĆ ULEPSZONĄ METODĘ EKSTRAKCJI}

\section{Wyniki}
Poniższe tabele przedstawiają otrzymane podczas badań wyniki:

%tabela 1

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla pierwszej metody ekstrakcji i metryki euklidesowej.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 87.86\%	%1
& 85.03\%	%2
& 89.56\%	%3
& 88.91\%	%4
& 89.87\%	%5
& 90.04\%	%6
& 90.41\%	%7
& 90.17\%	%8
& 90.50\%	%9
& 90.17\%	%10
& 89.36\%	%20
& 88.64\%	%30
& 88.05\%	%60
& 86.86\%	%100
& 90.17\% (k=8,10)
\\ \hline
Reuters
- topics
& 91.26\%	%1
& 86.41\%	%2
& 90.29\%	%3
& 88.35\%	%4
& 91.26\%	%5
& 91.75\%	%6
& 93.20\%	%7
& 92.72\%	%8
& 93.20\%	%9
& 92.23\%	%10
& 92.23\%	%20
& 91.26\%	%40
& 91.75\%	%60
& 92.72\%	%100
& 93.20\% (k=7,9)
\\ \hline
Przepisy
- kulinarne 
& 77.5\%	%1
& 80\%		%2
& 80\%		%3
& 77.5\%	%4
& 77.5\%	%5
& 80\%		%6
& 75\%		%7
& 77.5\%	%8
& 77.5\%	%9
& 80\%		%10
& 90\%		%20
& 77.5\%	%40
& ---		%60
& ---		%100
& 90\% (k=20)
\\ \hline
\end{longtable}
}
\endgroup


%tabela 2

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla pierwszej metody ekstrakcji i metryki manhattan.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 85.64\%	%1
& 71.25\%	%2
& 85.48\%	%3
& 74.63\%	%4
& 85.33\%	%5
& 84.52\%	%6
& 84.83\%	%7
& 84.29\%	%8
& 84.31\%	%9
& 83.92\%	%10
& 82.65\%	%20
& 81.26\%	%40
& 81.25\%	%60
& 81.23\%	%100
& 85.64\% (k=1)
\\ \hline
Reuters
- topics
& 91.26\%	%1
& 88.35\%	%2
& 89.81\%	%3
& 91.26\%	%4
& 91.26\%	%5
& 92.72\%	%6
& 91.75\%	%7
& 92.23\%	%8
& 91.75\%	%9
& 91.75\%	%10
& 91.75\%	%20
& 90.78\%	%40
& 89.32\%	%60
& 88.34\%	%100
& 92.72\%  (k=6)
\\ \hline
Przepisy
- kulinarne 
& 62.5\%	%1
& 57.5\%	%2
& 75\%		%3
& 62.5\%	%4
& 80\%		%5
& 72.5\%	%6
& 82.5\%	%7
& 75\%		%8
& 75\%		%9
& 77.5\%	%10
& 85\%		%20
& 82.5\%	%40
& ---		%60
& ---		%100
& 92.5\% (k=17)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 3

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla pierwszej metody ekstrakcji i metryki Czebyszewa.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 79.23\%	%1
& 72.71\%	%2
& 81.58\%	%3
& 81.67\%	%4
& 83.46\%	%5
& 83.70\%	%6
& 84.40\%	%7
& 84.29\%	%8
& 84.42\%	%9
& 84.52\%	%10
& 84.16\%	%20
& 83.09\%	%40
& 82.13\%	%60
& 81.41\%	%100
& 84.59\% (k=11)
\\ \hline
Reuters
- topics
& 75.73\%	%1
& 75.24\%	%2
& 74.76\%	%3
& 72.82\%	%4
& 70.87\%	%5
& 68.45\%	%6
& 68.93\%	%7
& 66.99\%	%8
& 66.99\%	%9
& 65.05\%	%10
& 57.28\%	%20
& 41.75\%	%40
& 34.95\%	%60
& 45.14\%	%100
& 75.73\%	(k=1)
\\ \hline
Przepisy
- kulinarne 
& 67.5\%	%1
& 72.5\%	%2
& 65\%		%3
& 75\%		%4
& 62.5\%	%5
& 67.5\%	%6
& 70\%		%7
& 72.5\%	%8
& 65\%		%9
& 72.5\%	%10
& 60\%		%20
& 52.5\%	%40
& ---		%60
& ---		%100
& 75\% (k=4)
\\ \hline
\end{longtable}
}
\endgroup




%tabela 4

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla podobieństwa tekstów za pomocą miary Jaccarda.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 88.30\%	%1
& 85.83\%	%2
& 89.70\%	%3
& 89.67\%	%4
& 89.67\%	%5
& 89.32\%	%6
& 89.63\%	%7
& 89.63\%	%8
& 89.62\%	%9
& 89.63\%	%10
& 88.71\%	%20
& 86.83\%	%40
& 85.55\%	%60
& 83.92\%	%100
& 89.70\%	(k=3)
\\ \hline
Reuters
- topics
& 85.92\%	%1
& 82.52\%	%2
& 83.98\%	%3
& 83.50\%	%4
& 86.41\%	%5
& 87.86\%	%6
& 87.86\%	%7
& 83.98\%	%8
& 86.89\%	%9
& 86.41\%	%10
& 86.89\%	%20
& 85.44\%	%40
& 81.55\%	%60
& 82.04\%	%100
& 87.86\%	(k=6,7)
\\ \hline
Przepisy
- kulinarne 
& 85\%		%1
& 80\%		%2
& 85\%		%3
& 82.5\%	%4
& 85\%		%5
& 82.5\%	%6
& 87.5\%	%7
& 82.5\%	%8
& 90\%		%9
& 82.5\%	%10
& 85\%		%20
& 87.5\%	%40
& ---		%60
& ---		%100
& 90\% (k=9)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 5

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla podobieństwa tekstów za pomocą n-gramów 4-elementowych.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 78.38\%	%1
& 75.96\%	%2
& 79.73\%	%3
& 79.36\%	%4
& 80.11\%	%5
& 80.14\%	%6
& 80.49\%	%7
& 80.34\%	%8
& 80.49\%	%9
& 80.38\%	%10
& 80.43\%	%20
& 80.24\%	%40
& 80.21\%	%60
& 80.24\%	%100
& 80.54\%	(k=16)
\\ \hline
Reuters
- topics
& 60.19\%	%1
& 57.77\%	%2
& 63.59\%	%3
& 61.17\%	%4
& 61.17\%	%5
& 59.71\%	%6
& 61.17\%	%7
& 59.71\%	%8
& 61.66\%	%9
& 61.66\%	%10
& 66.50\%	%20
& 71.36\%	%40
& 70.87\%	%60
& 74.27\%	%100
& 75.72\%	(k=97)
\\ \hline
Przepisy
- kulinarne 
& 77.5\%	%1
& 70\%		%2
& 82.5\%	%3
& 72.5\%	%4
& 75\%		%5
& 72.5\%	%6
& 82.5\%	%7
& 80\%		%8
& 87.5\%	%9
& 87.5\%	%10
& 82.5\%	%20
& 92.5\%	%40
& ---		%60
& ---		%100
& 95\% (k=41)
\\ \hline
\end{longtable}
}
\endgroup



%tabela 6

\begingroup
{\scriptsize  
\setlength{\LTleft}{-20cm plus -1fill}
\setlength{\LTright}{\LTleft}

\begin{longtable}{|p{1cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{1.1cm}|}
\caption{ Procent poprawnych wyników dla podobieństwa tekstów za pomocą zmodyfikowanej miary Jaccarda.}\\ 
\hline

Zbiór
dokumentów

 &\multicolumn{15}{c|}{Parametr k}\\
\cline{2-16}
& 1
& 2
& 3
& 4
& 5
& 6
& 7
& 8
& 9
& 10
& 20
& 40
& 60
& 100
& Najlepszy wynik
\\ \hline\hline
Reuters
- places
& 88.54\%	%1
& 85.64\%	%2
& 89.39\%	%3
& 89.49\%	%4
& 90.23\%	%5
& 89.89\%	%6
& 89.78\%	%7
& 89.87\%	%8
& 89.63\%	%9
& 89.65\%	%10
& 88.34\%	%20
& 86.66\%	%40
& 85.35\%	%60
& 83.70\%	%100

& 90.23\%	(k=5)
\\ \hline
Reuters
- topics
& 83.98\%	%1
& 82.52\%	%2
& 84.46\%	%3
& 86.41\%	%4
& 84.95\%	%5
& 88.35\%	%6
& 87.38\%	%7
& 85.44\%	%8
& 85.92\%	%9
& 85.44\%	%10
& 81.55\%	%20
& 80.10\%	%40
& 81.07\%	%60
& 81.07\%	%100

& 88.35\%	(k=6)
\\ \hline
Przepisy
- kulinarne 
& 92.5\%	%1
& 82.5\%	%2
& 80\%		%3
& 80\%		%4
& 80\%		%5
& 77.5\%	%6
& 80\%		%7
& 77.5\%	%8
& 85\%		%9
& 82.5\%	%10
& 85\%		%20
& 85\%		%40
& ---		%60
& ---		%100
& 92.5\% (k=1,13)
\\ \hline
\end{longtable}
}
\endgroup


\section{Dyskusja}
{\color{blue}
Sekcja ta powinna zawierać dokładną interpretację uzyskanych wyników
eksperymentów wraz ze szczegółowymi wnioskami z nich płynącymi. Najcenniejsze
są, rzecz jasna, wnioski o charakterze uniwersalnym, które mogą być istotne
przy innych, podobnych zadaniach. Należy również omówić i wyjaśnić wszystkie
napotakane problemy (jeśli takie były). Każdy wniosek powinien mieć poparcie
we wcześniej przeprowadzonych eksperymentach (odwołania do konkretnych
wyników). Jest to jedna z najważniejszych sekcji tego sprawozdania, gdyż
prezentuje poziom zrozumienia badanego problemu.}
\section{Wnioski}
{\color{blue}W tej, przedostatniej, sekcji należy zamieścić podsumowanie
najważniejszych wniosków z sekcji poprzedniej. Najlepiej jest je po prostu
wypunktować. Znów, tak jak poprzednio, najistotniejsze są wnioski o
charakterze uniwersalnym.}


\begin{thebibliography}{0}
\end{thebibliography}
{\color{blue} 
Na końcu należy obowiązkowo podać cytowaną w sprawozdaniu
literaturę, z której grupa korzystała w trakcie prac nad zadaniem (przykład na
końcu szablonu)}
\end{document}
